import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.optim import lr_scheduler
import matplotlib.pyplot as plt
from tqdm import tqdm
import numpy as np

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

num_epochs = 40
epoch_update = 5
batch_size = 200
learning_rate = 0.01
weight_decay_value = 0.001
rho_value = 0.9

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

class Swish(torch.nn.Module):
    def forward(self, x):
        return x * torch.sigmoid(x)


class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        self.network = nn.Sequential( 
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            Swish(),  # Instantiate Swish directly here
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            Swish(),
            nn.MaxPool2d(2, 2),  # output: 64 x 16 x 16

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            Swish(),
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            Swish(),
            nn.MaxPool2d(2, 2),  # output: 128 x 8 x 8

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            Swish(),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            Swish(),
            nn.MaxPool2d(2, 2),  # output: 256 x 4 x 4

            nn.Flatten(),
            nn.Dropout(),
            nn.Linear(256*4*4, 1024),
            nn.BatchNorm1d(1024),
            Swish(),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            Swish(),
            nn.Linear(512, 10)
        )

    def forward(self, x):
        return self.network(x)



model = ConvNet().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)


from time import time

t0=time()
models = []
for i in range(30):
    epoch_update = 40
    print("----------Model", (i+1), "----------")

    model = ConvNet().to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)
    
    
    for epoch in range(num_epochs):
        for i , (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)
    
            outputs = model(images)
            loss = criterion(outputs, labels)
    
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        if (epoch + 1) % epoch_update == 0:
            print(f'Epoch [{epoch + 1} / {num_epochs}], loss {loss.item():.4f}')
            model.eval()
            with torch.no_grad():
                n_correct = 0
                n_samples = 0
                n_class_correct = [0 for i in range(10)]
                n_class_samples = [0 for i in range(10)]
                print('=====TRAINING=====')
                for images, labels in train_loader:
                    images = images.to(device)
                    labels = labels.to(device)
                    outputs = model(images)
            
                    _, predicted = torch.max(outputs, 1)
                    n_samples += labels.size(0)
                    n_correct += (predicted == labels).sum().item()
            
                    for i in range(len(labels)):
                        label = labels[i]
                        pred = predicted[i]
                        if (label == pred):
                            n_class_correct[label] += 1
                        n_class_samples[label] += 1
                acc = 100.0 * n_correct / n_samples
                print(f'Accuracy of the network: {acc} %')
                for i in range(10):
                    acc = 100.0 * n_class_correct[i] / n_class_samples[i]
                    print(f'Accuracy of {classes[i]}: {acc} %')
                print('=====TESTING=====')
                n_correct = 0
                n_samples = 0
                n_class_correct = [0 for i in range(10)]
                n_class_samples = [0 for i in range(10)]
                for images, labels in test_loader:
                    images = images.to(device)
                    labels = labels.to(device)
                    outputs = model(images)
            
                    _, predicted = torch.max(outputs, 1)
                    n_samples += labels.size(0)
                    n_correct += (predicted == labels).sum().item()
            
                    for i in range(len(labels)):
                        label = labels[i]
                        pred = predicted[i]
                        if (label == pred):
                            n_class_correct[label] += 1
                        n_class_samples[label] += 1
                acc = 100.0 * n_correct / n_samples
                print(f'Accuracy of the network: {acc} %')
                for i in range(10):
                    acc = 100.0 * n_class_correct[i] / n_class_samples[i]
                    print(f'Accuracy of {classes[i]}: {acc} %')
                scheduler.step(acc)
                model.train()
        models.append(model)
        model.eval()
print(f"Elapsed Time: {(time() - t0):.3f} seconds")

from collections import Counter

def majority_vote(predictions, num_classes=10):
    class_votes = np.zeros((len(predictions), 1))
    for i, prediction in enumerate(predictions):
        element_counts = Counter(prediction)
        most_common_element = element_counts.most_common(1)[0][0]
        class_votes[i] = most_common_element
    return class_votes

all_predictions = []

with torch.no_grad():
    for model in models:
        model_predictions = []
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            model_predictions.extend(predicted.cpu().numpy())

        all_predictions.append(model_predictions)
predictions_matrix = np.column_stack(all_predictions)


test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)
test_data, test_labels = next(iter(test_loader))
test_labels_list = test_labels.cpu().numpy().tolist()

final_predictions = majority_vote(predictions_matrix)
final_predictions_flat = final_predictions.flatten()
samples = len(final_predictions_flat)  
correct = (final_predictions_flat == test_labels_list).sum() 
accuracy = correct / samples
print(f"Total Accuracy: {100 * accuracy:.4f} %")
